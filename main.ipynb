{"cells":[{"cell_type":"markdown","metadata":{},"source":["<br>\n","Name: arXiv Intelligence<br>\n","Authors: Jonathan CASSAING<br>\n","Highlighting the relationship between authors and scientists<br>\n","\n","**This Notebook file is provided for documentation purposes only**.<br>\n","It is not required in running the software. It was created from the \"main.py\" file.<br>\n","Please use the \"main.py\" file in production or development.<br>"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"]}],"source":["import time\n","import logging\n","import getopt\n","import sys\n","from pathlib import Path\n","from datetime import datetime\n","from progress.bar import IncrementalBar\n","from hdfs.util import HdfsError\n","from services.api.arxiv_api import ArxivApi\n","from services.api.ner_api import NerApi\n","from services.hdfs.hdfs_service import HdfsService\n","from services.ontology.ontology_service import OntologyService"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["PROGRAM_NAME = \"arXiv Intelligence\"\n","PROGRAM_VERSION = \"1.0.0\""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def print_help(script_name: str):\n","    \"\"\"Show the software CLI help\"\"\"\n","    print(script_name, '[options]\\n'\n","                       'This software highlights the relationships between authors and scientists, '\n","                       'from articles published on arxiv.org.'\n","                       'For this, it generates an ontology (owl file), '\n","                       'from the named entities located in the articles.\\n'\n","                       'After execution, the owl file is generated in the owl folder.\\n'\n","                       'The category is fixed to cs.AI.\\n'\n","                       '\\t-h | --help\\t\\t: show this help\\n'\n","                       '\\t-v | --version\\t\\t: show the version of this software\\n'\n","                       '\\t-w | --webservice=[url]\\t: set the url of the named entities web service '\n","                       '(you must use an instance of the following web service: '\n","                       'https://github.com/snook9/arxiv_intelligence_ner_ws)\\n'\n","                       'default value is http://localhost:5000/\\n'\n","                       '\\t-n | --number=[value]\\t: '\n","                       'set the max articles number extracted from arxiv.org\\n'\n","                       'default value is 2\\n'\n","                       '\\t-d | --hdfs\\t\\t: enable writing to HDFS for big data projects\\n'\n","                       'default disabled. Nota: HDFS server URL is hardcoded currently')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def parse_opt(script_name: str, argv):\n","    \"\"\"Parse options from CLI arguments\"\"\"\n","    options = {\"webservice\": \"http://localhost:5000/\", \"number\": 2, \"hdfs\": False}\n","    try:\n","        opts, _ = getopt.getopt(\n","            argv, \"hvw:n:d\",\n","            [\"help\", \"version\", \"webservice=\", \"number=\", \"hdfs\"])\n","    except getopt.GetoptError:\n","        print_help(script_name)\n","        sys.exit(2)\n","    for opt, arg in opts:\n","        if opt in (\"-h\", \"--help\"):\n","            print_help(script_name)\n","            sys.exit()\n","        elif opt in (\"-v\", \"--version\"):\n","            print(PROGRAM_NAME, PROGRAM_VERSION)\n","            sys.exit()\n","        elif opt in (\"-w\", \"--webservice\"):\n","            options[\"webservice\"] = arg\n","        elif opt in (\"-n\", \"--number\"):\n","            options[\"number\"] = int(arg)\n","        elif opt in (\"-d\", \"--hdfs\"):\n","            options[\"hdfs\"] = True\n","    return options"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["arXiv Intelligence 1.0.0\n","Events are logged in the folder: log\n","5 PDF file(s) retrieved\n","http://arxiv.org/pdf/2203.11194v1\n","http://arxiv.org/pdf/2203.11178v1\n","http://arxiv.org/pdf/2203.11176v1\n","http://arxiv.org/pdf/2203.11171v1\n","http://arxiv.org/pdf/2203.11146v1\n"]}],"source":["if __name__ == '__main__':\n","    # Get the user options (CLI arguments)\n","    # parse_opt is commented for Notebook file\n","    #cli_options = parse_opt(sys.argv[0], sys.argv[1:])\n","    # OPTIONS ARE HERE\n","    cli_options = {\"webservice\": \"http://localhost:5000/\", \"number\": 5, \"hdfs\": False}\n","\n","    # Print welcome message\n","    print(PROGRAM_NAME, PROGRAM_VERSION)\n","\n","    # We create the log folder\n","    log_folder = Path(\"log\")\n","    if False is log_folder.exists():\n","        # If the folder doesn't exist, we create it\n","        log_folder.mkdir()\n","    # Creating log config\n","    today = datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S.%f\")\n","    logging.basicConfig(filename=log_folder.joinpath(today + \".log\"), level=logging.DEBUG)\n","    print(\"Events are logged in the folder:\", log_folder)\n","\n","    # We retreive the PDF documents\n","    documents = ArxivApi(cli_options[\"number\"]).get_documents()\n","    print(len(documents), \"PDF file(s) retrieved\")\n","    logging.info(\"%s PDF file(s) retrieved\", len(documents))\n","\n","    for document in documents:\n","        print(document.pdf_url)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/name belongs to more than one entity types: [owl.DatatypeProperty, rdf-schema.label]; I'm trying to fix it...\n"]},{"name":"stdout","output_type":"stream","text":["ID: 662 | The file '2203.11194v1' has been received successfully!\n","ID: 662 | named entities retrieved\n","ID: 662 | named entities added to the ontology\n","ID: 663 | The file '2203.11178v1' has been received successfully!\n","ID: 663 | named entities retrieved\n","ID: 663 | named entities added to the ontology\n","ID: 664 | The file '2203.11176v1' has been received successfully!\n","ID: 664 | named entities retrieved\n","ID: 664 | named entities added to the ontology\n","ID: 665 | The file '2203.11171v1' has been received successfully!\n","ID: 665 | named entities retrieved\n","ID: 665 | named entities added to the ontology\n","ID: 666 | The file '2203.11146v1' has been received successfully!\n","ID: 666 | named entities retrieved\n","ID: 666 | named entities added to the ontology\n"]}],"source":["    # We instantiate an ontology\n","    ontology_service = OntologyService()\n","\n","    # We create a progress bar\n","    progress_bar = IncrementalBar('Processed files', max = len(documents))\n","\n","    # For each PDF document\n","    for document in documents:\n","        # We give the PDF URL to the NER Web Service\n","        ner_api = NerApi(cli_options[\"webservice\"])\n","        message = ner_api.post_document(document.pdf_url)\n","        if message is None:\n","            logging.error(\"Error while sending the file: %s\", document.pdf_url)\n","            print(\"Error while sending the file:\", document.pdf_url)\n","            # We wait few seconds before retry\n","            time.sleep(2)\n","            progress_bar.next()\n","            continue\n","        logging.info(\"ID: %s | %s\", message.object_id, message.message)\n","        print(\"ID:\", message.object_id, \"|\", message.message)\n","\n","        # If the PDF has been sent\n","        if message.object_id != -1:\n","            # Here, all it's ok, so we save the object id\n","            document.object_id = message.object_id\n","            # We init the status to pending for the while loop\n","            document.status = \"PENDING\"\n","            # We get the metadata of the PDF\n","            # As the process is async, we try the request several times\n","            # First, to calculate a timeout, we start a counter\n","            start_time = time.perf_counter_ns()\n","            TIMEOUT = False\n","            while document.status == \"PENDING\":\n","                # We check the elapsed time\n","                counter = (time.perf_counter_ns() - start_time) / 1000 / 1000 / 1000\n","                #Â If the elapsed time is more than 300 seconds\n","                if counter > 300:\n","                    # We leave the while loop\n","                    TIMEOUT = True\n","                    break\n","                # We wait few seconds to give the API time to process the file\n","                time.sleep(2)\n","                document_metadata = ner_api.get_document_metadata(document.object_id)\n","                # We keep the metadata\n","                try:\n","                    document.number_of_pages = document_metadata.number_of_pages\n","                    document.raw_info = document_metadata.raw_info\n","                    document.named_entities = document_metadata.named_entities\n","                    document.status = document_metadata.status\n","                except AttributeError as err:\n","                    logging.error(\"ID: %s | error when requesting metadata '%s'\",\n","                                  document.object_id, document.entry_id)\n","                    print(\"ID:\", document.object_id, \"| error when requesting metadata\", document.entry_id)\n","                    document.status = \"ERROR\"\n","                    break\n","\n","            # If timeout or an error occured\n","            if TIMEOUT is True or document.status == \"ERROR\":\n","                logging.error(\"ID: %s | error when extracting named entities of the document '%s', \\\n","                              timeout is '%s'\",\n","                              document.object_id, document.entry_id, TIMEOUT)\n","                print(\"ID:\", document.object_id, \"| error when extracting named entities of the document\", document.entry_id, \\\n","                             \"timeout is\", TIMEOUT)\n","                progress_bar.next()\n","                # Due to error, we skip to the next element of the loop\n","                continue\n","            logging.info(\"ID: %s | named entities retrieved\", document.object_id)\n","            print(\"ID:\", document.object_id, \"| named entities retrieved\")\n","\n","            # Then, we add each named entity of the document\n","            # to the ontology\n","            arxiv_onto_document = ontology_service.add_document(document)\n","            for named_entity in document.named_entities:\n","                ontology_service.add_named_entity(named_entity, arxiv_onto_document)\n","            logging.info(\"ID: %s | named entities added to the ontology\", document.object_id)\n","            print(\"ID:\", document.object_id, \"| named entities added to the ontology\",)\n","            # At the end of each PDF\n","            # We write the ontology in a folder\n","            filename = ontology_service.save(\"owl\")\n","            progress_bar.next()\n","    progress_bar.finish()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The ontology 'output_2022-03-22-22-41-21.676264.owl' has been saved!\n"]}],"source":["    # At the end\n","    # We finish the ontology, then write it\n","    ontology_service.finish()\n","    filename = ontology_service.save(\"owl\")\n","    print(\"The ontology '\" + filename + \"' has been saved!\")\n","    logging.info(\"The ontology '%s' has been saved!\", filename)\n","\n","    # If HDFS is enabled\n","    if cli_options[\"hdfs\"] is True:\n","        # Writing to HDFS (for big data projects)\n","        hdfs_service = HdfsService()\n","        csv_file = \"documents_\" + today + \".csv\"\n","        try:\n","            hdfs_service.write_documents(csv_file, documents)\n","            print(\"The file '\" + csv_file +\n","                  \"' has been saved to the following HDFS folder '\" +\n","                  str(hdfs_service.folder) + \"'\")\n","            logging.info(\"The file '%s' has been saved to the following HDFS folder '%s'\",\n","\t                     csv_file, str(hdfs_service.folder))\n","        except HdfsError as err:\n","            print(f\"HdfsError: {err}\")\n","            logging.error(\"HdfsError: '%s'\", err)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":2}
